{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBho0Wu0qh8V"
      },
      "source": [
        "# Quantization of models\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/toelt-llc/HSLU-WSCS_2025/blob/master/06%20-%20Quantization_of_models_Complete_examples.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "(C) Umberto Michelucci\n",
        "\n",
        "umberto.michelucci@toelt.ai\n",
        "\n",
        "www.toelt.ai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BKkuye8LUhTd",
        "outputId": "0428fafc-3a63-4d38-f86b-d5ddd32b02bb"
      },
      "outputs": [],
      "source": [
        "# !pip3 uninstall tensorflow\n",
        "# !pip3 install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yYGoCtibf6kW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-27 08:06:28.577250: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# DON'T USE THE FOLLOWING MAGIC COMMAND IN CASE YOU ARE INSTALLING TF-NIGHTLY.\n",
        "# IT WILL USE THE WRONG VERSION OF TENSORFLOW.\n",
        "#\n",
        "#try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  #%tensorflow_version 2.x\n",
        "#except Exception:\n",
        "#  pass\n",
        "\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OImOE832UFvx",
        "outputId": "fa47cae2-57d6-42c7-9cfa-fd80db746efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.16.2\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FCtliore7C5h"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if sys.version_info.major >= 3:\n",
        "    import pathlib\n",
        "else:\n",
        "    import pathlib2 as pathlib\n",
        "\n",
        "# Add `models` to the python path.\n",
        "models_path = os.path.join(os.getcwd(), \"models\")\n",
        "sys.path.append(models_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KcEjcH-c9tBy"
      },
      "outputs": [],
      "source": [
        "saved_models_root = \"/tmp/mnist_saved_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl1a5UN6fARV"
      },
      "source": [
        "#  Simple MNIST Model\n",
        "\n",
        "## Fitting and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sG_WziwEfPVD"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtDHIkd8gNGQ"
      },
      "source": [
        "We first import the `MNIST` dataset with the `tf.keras.datasets`. Note that we reshape the input into a `(60000, 784)` array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFNzes8zfPVH",
        "outputId": "809888b6-3fd6-4dc0-e223-3ad22efcc986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape((60000,784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQIfh5x2gY1t"
      },
      "source": [
        "We build a very dumb network with just one hidden layer with 128 neurons with `relu` activation functions. The output layer has 10 neurons (since we want to classify 10 classes) and then a `softmax` activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rpSzENPFjgN7"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "         optimizer=keras.optimizers.Adam(),\n",
        "         metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyUDcPUOfVCC",
        "outputId": "6630ffd0-3b80-43d7-a2c4-d927ad430152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.4365\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1174\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9763 - loss: 0.0784\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0605\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0451\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x13b4f8bf0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCFnQpbXglH_"
      },
      "source": [
        "The following cell will save the model. We will use this saved version in the next sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gEysXMAfVCS",
        "outputId": "fd2a0e1c-644c-4a3e-b11a-eb7985c9dfc5"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m export_dir = \u001b[33m\"\u001b[39m\u001b[33m/tmp/mnist\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaved_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1392\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, export_dir, signatures, options)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[32m   1391\u001b[39m metrics.IncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m metrics.IncrementWrite(write_version=\u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1427\u001b[39m, in \u001b[36msave_and_return_nodes\u001b[39m\u001b[34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[39m\n\u001b[32m   1423\u001b[39m saved_model = saved_model_pb2.SavedModel()\n\u001b[32m   1424\u001b[39m meta_graph_def = saved_model.meta_graphs.add()\n\u001b[32m   1426\u001b[39m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[32m-> \u001b[39m\u001b[32m1427\u001b[39m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1428\u001b[39m saved_model.saved_model_schema_version = (\n\u001b[32m   1429\u001b[39m     constants.SAVED_MODEL_SCHEMA_VERSION)\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1642\u001b[39m, in \u001b[36m_build_meta_graph\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1615\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[32m   1616\u001b[39m \n\u001b[32m   1617\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1638\u001b[39m \u001b[33;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[32m   1639\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1641\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save_context.save_context(options):\n\u001b[32m-> \u001b[39m\u001b[32m1642\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1552\u001b[39m, in \u001b[36m_build_meta_graph_impl\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1550\u001b[39m augmented_graph_view = _AugmentedGraphView(obj)\n\u001b[32m   1551\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1552\u001b[39m   signatures = \u001b[43msignature_serialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_function_to_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1553\u001b[39m \u001b[43m      \u001b[49m\u001b[43maugmented_graph_view\u001b[49m\n\u001b[32m   1554\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m signatures, wrapped_functions, defaults = (\n\u001b[32m   1557\u001b[39m     signature_serialization.canonicalize_signatures(signatures)\n\u001b[32m   1558\u001b[39m )\n\u001b[32m   1559\u001b[39m signature_serialization.validate_augmented_graph_view(augmented_graph_view)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/signature_serialization.py:109\u001b[39m, in \u001b[36mfind_function_to_export\u001b[39m\u001b[34m(saveable_view)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[32m    108\u001b[39m possible_signatures = []\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdef_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConcreteFunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:190\u001b[39m, in \u001b[36m_AugmentedGraphView.list_children\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._children_cache:\n\u001b[32m    188\u001b[39m   children = \u001b[38;5;28mself\u001b[39m._children_cache[obj] = {}\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSaveType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun.ConcreteFunction):\n\u001b[32m    195\u001b[39m       child = \u001b[38;5;28mself\u001b[39m._maybe_uncache_variable_captures(child)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[39m, in \u001b[36mObjectGraphView.list_children\u001b[39m\u001b[34m(self, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m children = []\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.items():\n\u001b[32m     77\u001b[39m   children.append(base.TrackableReference(name, ref))\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/checkpoint/trackable_view.py:85\u001b[39m, in \u001b[36mTrackableView.children\u001b[39m\u001b[34m(cls, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m children = {}\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj._trackable_children(save_type, **kwargs).items():\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m   ref = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_trackable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m   children[name] = ref\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/trackable/converter.py:31\u001b[39m, in \u001b[36mconvert_to_trackable\u001b[39m\u001b[34m(obj, parent)\u001b[39m\n\u001b[32m     29\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m     30\u001b[39m obj = data_structures.wrap_or_unwrap(obj)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtensor_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_tf_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     32\u001b[39m     obj.dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (dtypes.variant, dtypes.resource) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m resource_variable_ops.is_resource_variable(obj)):\n\u001b[32m     34\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_utils.TrackableConstant(obj, parent)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base.Trackable):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/site-packages/tensorflow/python/framework/tensor_util.py:1156\u001b[39m, in \u001b[36mis_tf_type\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1128\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mis_tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[32m   1130\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[32m   1131\u001b[39m \n\u001b[32m   1132\u001b[39m \u001b[33;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1154\u001b[39m \u001b[33;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[32m   1155\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_type_classes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/typing.py:1868\u001b[39m, in \u001b[36m_ProtocolMeta.__instancecheck__\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n\u001b[32m   1866\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__protocol_attrs__:\n\u001b[32m   1867\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1868\u001b[39m         val = \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1869\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1870\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/inspect.py:1839\u001b[39m, in \u001b[36mgetattr_static\u001b[39m\u001b[34m(obj, attr, default)\u001b[39m\n\u001b[32m   1836\u001b[39m     dict_attr = _shadowed_dict(klass)\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types.MemberDescriptorType):\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m         instance_result = \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1841\u001b[39m     klass = obj\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/wscs/lib/python3.12/inspect.py:1793\u001b[39m, in \u001b[36m_check_instance\u001b[39m\u001b[34m(obj, attr)\u001b[39m\n\u001b[32m   1791\u001b[39m instance_dict = {}\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m     instance_dict = \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__dict__\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: this __dict__ descriptor does not support '_DictWrapper' objects"
          ]
        }
      ],
      "source": [
        "export_dir = \"/tmp/mnist\"\n",
        "tf.saved_model.save(model, export_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEQdvkdffZ3R"
      },
      "source": [
        "# Plain Conversion (without quantization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z-xh1UkguDu"
      },
      "source": [
        "As a first step, we can simply convert the model without any quantization. Basically we simply change its format to `TFLite` but we will not change any weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoxB3ogC93EQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.experimental_new_converter = True # otherwise you get a warning\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDlobhPj96Gw"
      },
      "outputs": [],
      "source": [
        "tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KFBt_9N98kR",
        "outputId": "9a08e966-993b-4ae8-b583-9c903cf17940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(408768,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B1pgkn98mLDb",
        "outputId": "bd7870dc-3940-47e2-8ab1-7a74fbb7b7a2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0ee32af9-c3bb-4350-a412-2432dee72012\", \"mnist_model.tflite\", 408768)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(tflite_models_dir/\"mnist_model.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhXQnmG29_Cc"
      },
      "source": [
        "## Convert with weight quantization to 8-bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vDE-zC_g34o"
      },
      "source": [
        "The following `optimizations` will quantize the weights to 8-bits. So the converted model will have a reduced size as you can see below in the last cell of this section. Note that going from 32-bit to 8-bit will reduce the model size of 1/4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4KmgDim-C2c"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3K8xn9b-IdE",
        "outputId": "ae3e3695-8495-4666-bf32-54adfd1c1bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "104024"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tflite_model_quant = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "07_Ul2m2yPCl",
        "outputId": "c8529ead-0a73-4b53-b475-2fb7a7211a37"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4bca4012-1557-4984-a1da-778290612b29\", \"mnist_model_quant.tflite\", 104024)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(tflite_models_dir/\"mnist_model_quant.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVzEXqGZ-KOR",
        "outputId": "868cf4a9-36fe-47fd-e3f2-845acf79c3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 504K\n",
            "-rw-r--r-- 1 root root 102K Sep  4 14:12 mnist_model_quant.tflite\n",
            "-rw-r--r-- 1 root root 400K Sep  4 14:11 mnist_model.tflite\n"
          ]
        }
      ],
      "source": [
        "!ls -lh {tflite_models_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1OUBl64gnUs"
      },
      "source": [
        "# Evaluation of accuracy of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEzYizJ-VdI"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ughD5iE1-Wpu"
      },
      "outputs": [],
      "source": [
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTaEZcpo-YCH"
      },
      "outputs": [],
      "source": [
        "image_1 = x_train[0].astype(np.float32)\n",
        "image_1 = image_1.reshape(1,784)\n",
        "\n",
        "interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image_1)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(\n",
        "    interpreter.get_output_details()[0][\"index\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMxrzEN5-Zwv",
        "outputId": "81e147a5-d841-4ac8-e192-6f706026448d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(predictions))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjtz1VIu-a1K"
      },
      "source": [
        "Now test the quantized model (using the uint8 data):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpi7pxwy-eVP"
      },
      "outputs": [],
      "source": [
        "image_1 = x_train[0].astype(np.float32)\n",
        "image_1 = image_1.reshape(1,784)\n",
        "\n",
        "interpreter_quant.set_tensor(\n",
        "    interpreter_quant.get_input_details()[0][\"index\"], image_1)\n",
        "interpreter_quant.invoke()\n",
        "predictions = interpreter_quant.get_tensor(\n",
        "    interpreter_quant.get_output_details()[0][\"index\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbHVXcQp-kq8",
        "outputId": "aa456172-8097-4cee-d0f1-37b21a0fb8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(predictions))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFEC_hMOijbQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "wscs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
