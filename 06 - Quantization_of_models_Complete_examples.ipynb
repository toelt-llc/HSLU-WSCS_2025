{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBho0Wu0qh8V"
      },
      "source": [
        "# Quantization of models\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/toelt-llc/HSLU-WSCS_2025/blob/master/06%20-%20Quantization_of_models_Complete_examples.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "(C) Umberto Michelucci\n",
        "\n",
        "umberto.michelucci@toelt.ai\n",
        "\n",
        "www.toelt.ai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BKkuye8LUhTd",
        "outputId": "0428fafc-3a63-4d38-f86b-d5ddd32b02bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.1.0rc1:\n",
            "  Would remove:\n",
            "    /tensorflow-2.1.0/python3.6/tensorflow-2.1.0rc1.dist-info/*\n",
            "    /tensorflow-2.1.0/python3.6/tensorflow/*\n",
            "    /tensorflow-2.1.0/python3.6/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.1.0rc1\n",
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/c5/b0217554ef2b896042f6b78f0bd6e3dfc707d7c467a20ae219ab178d92cc/tf_nightly-2.2.0.dev20200113-cp36-cp36m-manylinux2010_x86_64.whl (449.5MB)\n",
            "\u001b[K     |████████████████████████████████| 449.5MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /tensorflow-2.1.0/python3.6 (from tf-nightly) (0.33.6)\n",
            "Collecting tb-nightly<2.3.0a0,>=2.2.0a0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/32/0379b65809c879b75a736f667c01cc59a9a0c8d760670b04a12b62078388/tb_nightly-2.2.0a20200106-py3-none-any.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 30.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.13.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (2.10.0)\n",
            "Collecting tf-estimator-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/92/a7d06f4d28090d0d8cb0e960942d7eafc50f4de45b6629966dfac8ff47e7/tf_estimator_nightly-2.0.0.dev2020011309-py2.py3-none-any.whl (453kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (0.1.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.18.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (3.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.26.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.11.2)\n",
            "Collecting gast==0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (44.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.10.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.22.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.2.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (1.25.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.3.0a0,>=2.2.0a0->tf-nightly) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.3.2-cp36-none-any.whl size=9679 sha256=4538b00e0acd6a7d1bc349b33aa724d6b857dd16d812303cc0ce86f1baefd228\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tb-nightly, tf-estimator-nightly, gast, tf-nightly\n",
            "  Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "Successfully installed gast-0.3.2 tb-nightly-2.2.0a20200106 tf-estimator-nightly-2.0.0.dev2020011309 tf-nightly-2.2.0.dev20200113\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install tf-nightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYGoCtibf6kW"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# DON'T USE THE FOLLOWING MAGIC COMMAND IN CASE YOU ARE INSTALLING TF-NIGHTLY.\n",
        "# IT WILL USE THE WRONG VERSION OF TENSORFLOW.\n",
        "#\n",
        "#try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  #%tensorflow_version 2.x\n",
        "#except Exception:\n",
        "#  pass\n",
        "\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OImOE832UFvx",
        "outputId": "fa47cae2-57d6-42c7-9cfa-fd80db746efe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCtliore7C5h"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if sys.version_info.major >= 3:\n",
        "    import pathlib\n",
        "else:\n",
        "    import pathlib2 as pathlib\n",
        "\n",
        "# Add `models` to the python path.\n",
        "models_path = os.path.join(os.getcwd(), \"models\")\n",
        "sys.path.append(models_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcEjcH-c9tBy"
      },
      "outputs": [],
      "source": [
        "saved_models_root = \"/tmp/mnist_saved_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl1a5UN6fARV"
      },
      "source": [
        "#  Simple MNIST Model\n",
        "\n",
        "## Fitting and saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG_WziwEfPVD"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtDHIkd8gNGQ"
      },
      "source": [
        "We first import the `MNIST` dataset with the `tf.keras.datasets`. Note that we reshape the input into a `(60000, 784)` array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFNzes8zfPVH",
        "outputId": "809888b6-3fd6-4dc0-e223-3ad22efcc986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "(60000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "print(x_train.shape)\n",
        "\n",
        "x_train = x_train.reshape((60000,784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQIfh5x2gY1t"
      },
      "source": [
        "We build a very dumb network with just one hidden layer with 128 neurons with `relu` activation functions. The output layer has 10 neurons (since we want to classify 10 classes) and then a `softmax` activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpSzENPFjgN7"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
        "         optimizer=keras.optimizers.Adam(),\n",
        "         metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyUDcPUOfVCC",
        "outputId": "6630ffd0-3b80-43d7-a2c4-d927ad430152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2555 - accuracy: 0.9280\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1143 - accuracy: 0.9667\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0784 - accuracy: 0.9767\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0580 - accuracy: 0.9819\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0451 - accuracy: 0.9862\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a518aa258a0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCFnQpbXglH_"
      },
      "source": [
        "The following cell will save the model. We will use this saved version in the next sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gEysXMAfVCS",
        "outputId": "fd2a0e1c-644c-4a3e-b11a-eb7985c9dfc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "export_dir = \"/tmp/mnist\"\n",
        "tf.saved_model.save(model, export_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEQdvkdffZ3R"
      },
      "source": [
        "# Plain Conversion (without quantization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z-xh1UkguDu"
      },
      "source": [
        "As a first step, we can simply convert the model without any quantization. Basically we simply change its format to `TFLite` but we will not change any weight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoxB3ogC93EQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "converter.experimental_new_converter = True # otherwise you get a warning\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDlobhPj96Gw"
      },
      "outputs": [],
      "source": [
        "tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
        "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KFBt_9N98kR",
        "outputId": "9a08e966-993b-4ae8-b583-9c903cf17940"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(408768,)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
        "tflite_model_file.write_bytes(tflite_model),"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B1pgkn98mLDb",
        "outputId": "bd7870dc-3940-47e2-8ab1-7a74fbb7b7a2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_0ee32af9-c3bb-4350-a412-2432dee72012\", \"mnist_model.tflite\", 408768)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(tflite_models_dir/\"mnist_model.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhXQnmG29_Cc"
      },
      "source": [
        "## Convert with weight quantization to 8-bits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vDE-zC_g34o"
      },
      "source": [
        "The following `optimizations` will quantize the weights to 8-bits. So the converted model will have a reduced size as you can see below in the last cell of this section. Note that going from 32-bit to 8-bit will reduce the model size of 1/4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4KmgDim-C2c"
      },
      "outputs": [],
      "source": [
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3K8xn9b-IdE",
        "outputId": "ae3e3695-8495-4666-bf32-54adfd1c1bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
            "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "104024"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tflite_model_quant = converter.convert()\n",
        "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
        "tflite_model_quant_file.write_bytes(tflite_model_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "07_Ul2m2yPCl",
        "outputId": "c8529ead-0a73-4b53-b475-2fb7a7211a37"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4bca4012-1557-4984-a1da-778290612b29\", \"mnist_model_quant.tflite\", 104024)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(tflite_models_dir/\"mnist_model_quant.tflite\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVzEXqGZ-KOR",
        "outputId": "868cf4a9-36fe-47fd-e3f2-845acf79c3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 504K\n",
            "-rw-r--r-- 1 root root 102K Sep  4 14:12 mnist_model_quant.tflite\n",
            "-rw-r--r-- 1 root root 400K Sep  4 14:11 mnist_model.tflite\n"
          ]
        }
      ],
      "source": [
        "!ls -lh {tflite_models_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1OUBl64gnUs"
      },
      "source": [
        "# Evaluation of accuracy of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEEzYizJ-VdI"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file))\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ughD5iE1-Wpu"
      },
      "outputs": [],
      "source": [
        "interpreter_quant = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))\n",
        "interpreter_quant.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTaEZcpo-YCH"
      },
      "outputs": [],
      "source": [
        "image_1 = x_train[0].astype(np.float32)\n",
        "image_1 = image_1.reshape(1,784)\n",
        "\n",
        "interpreter.set_tensor(interpreter.get_input_details()[0][\"index\"], image_1)\n",
        "interpreter.invoke()\n",
        "predictions = interpreter.get_tensor(\n",
        "    interpreter.get_output_details()[0][\"index\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMxrzEN5-Zwv",
        "outputId": "81e147a5-d841-4ac8-e192-6f706026448d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(predictions))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjtz1VIu-a1K"
      },
      "source": [
        "Now test the quantized model (using the uint8 data):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpi7pxwy-eVP"
      },
      "outputs": [],
      "source": [
        "image_1 = x_train[0].astype(np.float32)\n",
        "image_1 = image_1.reshape(1,784)\n",
        "\n",
        "interpreter_quant.set_tensor(\n",
        "    interpreter_quant.get_input_details()[0][\"index\"], image_1)\n",
        "interpreter_quant.invoke()\n",
        "predictions = interpreter_quant.get_tensor(\n",
        "    interpreter_quant.get_output_details()[0][\"index\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbHVXcQp-kq8",
        "outputId": "aa456172-8097-4cee-d0f1-37b21a0fb8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "print(np.argmax(predictions))\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFEC_hMOijbQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
